# Multi-Vendor Sample Data

This directory contains comprehensive sample data for 12 major AI/cloud vendors across multiple regions and time periods.

## üìä Dataset Overview

### **Companies Included:**
1. **Amazon Web Services** - Cloud infrastructure leader
2. **Google Cloud Platform** - AI/ML focused cloud provider
3. **Microsoft Azure** - Enterprise cloud platform
4. **OpenAI** - Leading AI research company
5. **Anthropic** - AI safety focused company
6. **Hugging Face** - Open-source AI platform
7. **Cohere** - Enterprise AI company
8. **Stability AI** - AI image generation company
9. **Meta AI** - Social media AI research
10. **NVIDIA** - GPU and AI hardware company
11. **IBM Watson** - Enterprise AI services
12. **Oracle Cloud** - Enterprise cloud platform
13. **Salesforce Einstein** - CRM AI platform

### **Data Coverage:**
- **Time Period**: Q1 2024 (January - March)
- **Total Records**: 39 data points
- **Regions**: 8 different geographic regions
- **Metrics**: Complete operational data for all vendors

## üèÜ Expected Performance Rankings

Based on the sample data, here's the expected ranking order:

### **Tier 1: Industry Leaders (90+ Green Score)**
1. **Google Cloud Platform** - 95.2/100
   - Excellent PUE (1.12), high utilization (89-91%)
   - Strong renewable energy usage
   
2. **Amazon Web Services** - 94.8/100
   - Very good PUE (1.15), excellent utilization (90-94%)
   - Large scale operations with good efficiency

3. **NVIDIA** - 94.1/100
   - Good PUE (1.16), high utilization (88-92%)
   - Hardware optimization expertise

### **Tier 2: Strong Performers (80-90 Green Score)**
4. **Microsoft Azure** - 87.3/100
   - Moderate PUE (1.18), good utilization (86-90%)
   - Solid enterprise focus

5. **Meta AI** - 85.7/100
   - Good PUE (1.22), high utilization (84-88%)
   - Research-focused operations

6. **OpenAI** - 82.4/100
   - Higher PUE (1.20), good utilization (83-87%)
   - AI research intensive

### **Tier 3: Developing (70-80 Green Score)**
7. **Anthropic** - 78.9/100
   - Higher PUE (1.25), moderate utilization (80-84%)
   - Smaller scale operations

8. **IBM Watson** - 76.2/100
   - Higher PUE (1.28), moderate utilization (77-81%)
   - Legacy enterprise focus

9. **Hugging Face** - 74.1/100
   - Higher PUE (1.30), lower utilization (76-80%)
   - Open-source community focus

### **Tier 4: Emerging (60-70 Green Score)**
10. **Oracle Cloud** - 71.8/100
    - Higher PUE (1.32), lower utilization (74-78%)
    - Enterprise cloud transition

11. **Cohere** - 69.5/100
    - Higher PUE (1.35), lower utilization (73-77%)
    - Startup scale operations

12. **Salesforce Einstein** - 67.2/100
    - Higher PUE (1.38), lower utilization (72-76%)
    - CRM-focused AI

13. **Stability AI** - 64.9/100
    - Highest PUE (1.40), lowest utilization (70-74%)
    - Image generation intensive

## üìà Key Insights

### **Efficiency Patterns:**
- **PUE Range**: 1.12 (Google) to 1.40 (Stability AI)
- **Utilization Range**: 70% (Stability AI) to 94% (AWS)
- **Scale Correlation**: Larger companies tend to have better efficiency
- **Regional Variations**: US regions generally more efficient

### **Carbon Intensity Trends:**
- **Best Performers**: Google, AWS, NVIDIA (under 200 gCO‚ÇÇ/1k tokens)
- **Moderate Performers**: Azure, Meta, OpenAI (200-300 gCO‚ÇÇ/1k tokens)
- **Higher Intensity**: Smaller companies with higher PUE values

### **Data Quality:**
- **Completeness**: 100% - all required and optional fields populated
- **Consistency**: Standardized formats and realistic values
- **Validation**: All metrics within expected industry ranges

## üåç Regional Distribution

### **US Regions:**
- **US-VA**: Amazon Web Services (primary data center)
- **US-CA**: Google, OpenAI, Anthropic, Stability AI, Salesforce
- **US-WA**: Microsoft Azure
- **US-TX**: Meta AI
- **US-NY**: IBM Watson
- **US-OR**: Oracle Cloud

### **International Regions:**
- **EU-FR**: Hugging Face (European operations)
- **CA-ON**: Cohere (Canadian operations)

## üîß Technical Specifications

### **Data Format:**
- **CSV**: 39 rows √ó 9 columns
- **JSON**: 39 objects with nested structure
- **File Size**: ~3KB (CSV), ~8KB (JSON)
- **Encoding**: UTF-8

### **Validation:**
- ‚úÖ All required columns present
- ‚úÖ Data types correct
- ‚úÖ Value ranges realistic
- ‚úÖ No missing values
- ‚úÖ Consistent naming conventions

## üéØ Use Cases

### **1. Comprehensive Testing**
- Test ranking algorithms with realistic data
- Validate multi-vendor comparison logic
- Verify regional carbon intensity calculations

### **2. Benchmarking**
- Compare vendor performance across metrics
- Understand industry efficiency ranges
- Identify best practices

### **3. Procurement Scenarios**
- Multi-vendor RFP evaluation
- Cost-benefit analysis
- Risk assessment

### **4. Research & Analysis**
- Industry trend analysis
- Efficiency correlation studies
- Regional carbon impact assessment

## üìã Expected Processing Results

When uploaded and processed, this data should result in:

### **Rankings:**
- Clear performance tiers
- Realistic Green Score distribution
- Meaningful vendor comparisons

### **Metrics:**
- Total emissions: ~500-600 tCO‚ÇÇe across all vendors
- Average utilization: ~82%
- Average PUE: ~1.25
- Carbon intensity range: 150-400 gCO‚ÇÇ/1k tokens

### **Insights:**
- Scale efficiency benefits
- Regional carbon intensity variations
- Technology stack impact on efficiency

## üöÄ How to Use

### **1. Download Files**
- Use the file upload feature in the dashboard
- Download CSV or JSON format as needed
- All files contain identical data in different formats

### **2. Upload and Process**
- Upload via the web interface
- Enable auto-processing for immediate results
- Review rankings and detailed metrics

### **3. Analyze Results**
- Compare vendor performance
- Review carbon efficiency rankings
- Identify procurement recommendations

## üìö Related Files

- `sample_multi_vendor_data.csv` - CSV format
- `sample_multi_vendor_data.json` - JSON format
- `sample_amazon_data.*` - Single vendor examples
- `sample_vendor_data.csv` - Basic template

## üîç Data Quality Notes

- **Realistic Values**: Based on industry benchmarks and public data
- **Consistent Scaling**: Proportional to company size and focus
- **Regional Accuracy**: Reflects actual data center locations
- **Temporal Consistency**: Logical month-over-month variations

This dataset provides a comprehensive foundation for testing and demonstrating the Carbon Ranker system's capabilities across a diverse range of AI and cloud vendors.
